{
  "metadata": {
    "title": "HPO Over FB15K-237 for ERMLP"
  },
  "pipeline": {
    "dataset": "fb15k237",
    "dataset_kwargs": {
      "create_inverse_triples": false
    },
    "model": "ERMLP",
    "model_kwargs_ranges": {
      "embedding_dim": {
        "type": "int",
        "low": 50,
        "high": 200,
        "q": 50
      }
    },
    "loss": "BCEAfterSigmoidLoss",
    "regularizer": "NoRegularizer",
    "optimizer": "adam",
    "optimizer_kwargs": {
      "weight_decay": 0.0
    },
    "optimizer_kwargs_ranges": {
      "lr": {
        "type": "float",
        "low": 0.001,
        "high": 0.1,
        "scale": "log"
      }
    },
    "training_loop": "owa",
    "negative_sampler": "BasicNegativeSampler",
    "negative_sampler_kwargs_ranges": {
      "num_negs_per_pos": {
        "type": "int",
        "low": 1,
        "high": 100,
        "q": 10
      }
    },
    "training_kwargs": {
      "batch_size": 256,
      "sub_batch_size": 64,
      "label_smoothing": 0.0
    },
    "training_kwargs_ranges": {
      "num_epochs": {
        "type": "int",
        "low": 500,
        "high": 2000,
        "q": 100
      }
    },
    "evaluator": "RankBasedEvaluator",
    "evaluator_kwargs": {
      "filtered": true
    },
    "evaluation_kwargs": {
      "batch_size": 1
    }
  },
  "optuna": {
    "n_trials": 100,
    "timeout": 86400,
    "metric": "hits@10",
    "direction": "maximize",
    "sampler": "random",
    "pruner": "nop"
  }
}